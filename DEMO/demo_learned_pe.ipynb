{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-00",
   "metadata": {},
   "source": [
    "# Learned Positional Encoding — Demo\n",
    "\n",
    "**Used in:** BERT, GPT-2, and many standard transformer models  \n",
    "**Formula:** `PE = Embedding(pos_ids)`  — a trainable lookup table  \n",
    "**Properties:** Task-specific | Fully flexible | Requires data | Fixed max length  \n",
    "**Best for:** Fixed-length tasks with large training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Learned PE: a trainable nn.Embedding table.\n",
    "    One d_model vector per position, optimized end-to-end.\n",
    "    Initialized with small normal noise (GPT-2 style: std=0.02).\n",
    "    '''\n",
    "    def __init__(self, d_model, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.pe = nn.Embedding(max_seq_len, d_model)\n",
    "        nn.init.normal_(self.pe.weight, mean=0.0, std=0.02)  # GPT-style init\n",
    "\n",
    "        print(f'Learned PE: {max_seq_len} positions x {d_model} dims = {max_seq_len * d_model} params')\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        positions = torch.arange(seq_len, device=x.device)\n",
    "        pe = self.pe(positions).unsqueeze(0)  # (1, seq_len, d_model)\n",
    "        x = x + pe\n",
    "        return self.dropout(x)\n",
    "\n",
    "print('LearnedPositionalEncoding defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "d_model, seq_len, batch = 64, 50, 4\n",
    "pe_layer = LearnedPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "x = torch.zeros(batch, seq_len, d_model)\n",
    "out = pe_layer(x)\n",
    "\n",
    "print(f'Input shape : {x.shape}')\n",
    "print(f'Output shape: {out.shape}')\n",
    "print(f'Learnable params: {sum(p.numel() for p in pe_layer.parameters())}')  # 512 * d_model\n",
    "\n",
    "# Each position has a unique vector\n",
    "pe_vecs = pe_layer.pe.weight[:5].detach()  # first 5 positions\n",
    "similarity = torch.cosine_similarity(pe_vecs[0].unsqueeze(0), pe_vecs, dim=-1)\n",
    "print(f'\\nCosine similarity of pos 0 with pos 0-4: {similarity.tolist()}')\n",
    "print('(Initialized randomly — similarities should be low, ~0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap — initial (random) embeddings before training\n",
    "d_model, seq_len = 64, 60\n",
    "pe_layer = LearnedPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "pe_matrix = pe_layer.pe.weight[:seq_len].detach().numpy()  # (seq_len, d_model)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "im = axes[0].imshow(pe_matrix.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Dimension')\n",
    "axes[0].set_title('Learned PE (BEFORE training — random init)')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Cosine similarity matrix between positions\n",
    "pe_norm = pe_matrix / (np.linalg.norm(pe_matrix, axis=1, keepdims=True) + 1e-8)\n",
    "sim_matrix = pe_norm @ pe_norm.T\n",
    "im2 = axes[1].imshow(sim_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Position')\n",
    "axes[1].set_title('Position Similarity Matrix (before training)')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_learned_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: demo_learned_heatmap.png')\n",
    "print('Note: After training, learned PE will develop meaningful position structure.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model, max_seq_len = 64, 512\n",
    "print('=== Learned PE Summary ===')\n",
    "print(f'Learnable parameters: {max_seq_len} x {d_model} = {max_seq_len * d_model}')\n",
    "print('Initialized: Normal(0, 0.02) — GPT-2 style')\n",
    "print('Task-adaptive: YES (learned end-to-end)')\n",
    "print('Generalizes to unseen lengths: NO (fixed max_seq_len)')\n",
    "print('Used in: BERT, GPT-2')\n",
    "print()\n",
    "print('Ready to use in experiments.')\n",
    "print('Import: from PE.learned_pe import LearnedPositionalEncoding')"
   ]
  }
 ]
}
