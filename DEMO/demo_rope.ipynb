{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-00",
   "metadata": {},
   "source": [
    "# RoPE — Rotary Position Embedding Demo\n",
    "\n",
    "**Paper:** Su et al. (2021) — *RoFormer: Enhanced Transformer with Rotary Position Embedding*  \n",
    "**Used in:** LLaMA, GPT-NeoX, Falcon, Mistral, and most modern LLMs  \n",
    "**Formula:** `x_rotated = x * cos(θ) + rotate_half(x) * sin(θ)`  \n",
    "**Properties:** No learnable params | Encodes relative positions | SOTA for LLMs  \n",
    "**Note:** Canonical RoPE rotates Q/K in attention. This demo applies it to embeddings for unified comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPEPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Rotary Position Embedding (RoPE) — Su et al. (2021)\n",
    "    Applies rotation to embeddings using position-dependent angles.\n",
    "    theta_i = 1 / 10000^(2i/d_model)\n",
    "    x_rotated = x * cos(pos * theta) + rotate_half(x) * sin(pos * theta)\n",
    "    '''\n",
    "    def __init__(self, d_model, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Rotation frequencies\n",
    "        theta = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))\n",
    "        positions = torch.arange(max_seq_len, dtype=torch.float)\n",
    "        angles = torch.outer(positions, theta)  # (max_seq_len, d_model/2)\n",
    "\n",
    "        self.register_buffer('cos', torch.cos(angles))\n",
    "        self.register_buffer('sin', torch.sin(angles))\n",
    "\n",
    "    def _rotate_half(self, x):\n",
    "        half = x.shape[-1] // 2\n",
    "        x1, x2 = x[..., :half], x[..., half:]\n",
    "        return torch.cat([-x2, x1], dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        cos = torch.cat([self.cos[:seq_len], self.cos[:seq_len]], dim=-1).unsqueeze(0)\n",
    "        sin = torch.cat([self.sin[:seq_len], self.sin[:seq_len]], dim=-1).unsqueeze(0)\n",
    "        return self.dropout(x * cos + self._rotate_half(x) * sin)\n",
    "\n",
    "print('RoPEPositionalEncoding defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check — shape + relative position property\n",
    "d_model, seq_len, batch = 64, 50, 4\n",
    "pe_layer = RoPEPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "x = torch.randn(batch, seq_len, d_model)\n",
    "out = pe_layer(x)\n",
    "\n",
    "print(f'Input shape : {x.shape}')\n",
    "print(f'Output shape: {out.shape}')\n",
    "print(f'Learnable params: {sum(p.numel() for p in pe_layer.parameters())}')  # should be 0\n",
    "\n",
    "# RoPE property: rotation preserves vector magnitude\n",
    "input_norm = x[0, :5].norm(dim=-1)\n",
    "output_norm = out[0, :5].norm(dim=-1)\n",
    "print(f'\\nInput norms  (first 5 pos): {input_norm.detach().tolist()}')\n",
    "print(f'Output norms (first 5 pos): {output_norm.detach().tolist()}')\n",
    "print('(Norms should be ~equal — rotation preserves magnitude)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap — visualize cos/sin patterns and effective PE\n",
    "d_model, seq_len = 64, 60\n",
    "pe_layer = RoPEPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "# The cos component across positions and dimensions\n",
    "cos_matrix = torch.cat([pe_layer.cos[:seq_len], pe_layer.cos[:seq_len]], dim=-1).numpy()\n",
    "\n",
    "# What RoPE does to a uniform input\n",
    "uniform_x = torch.ones(1, seq_len, d_model)\n",
    "with torch.no_grad():\n",
    "    encoded = pe_layer(uniform_x)\n",
    "pe_matrix = encoded[0].numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "im0 = axes[0].imshow(cos_matrix.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Dimension')\n",
    "axes[0].set_title('RoPE cos(theta) pattern')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "im1 = axes[1].imshow(pe_matrix.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Dimension')\n",
    "axes[1].set_title('RoPE applied to uniform input')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_rope_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: demo_rope_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== RoPE Summary ===')\n",
    "print('Learnable parameters: 0')\n",
    "print('Encodes relative positions: YES')\n",
    "print('Preserves vector magnitude: YES (rotation is isometric)')\n",
    "print('Generalizes to unseen lengths: YES')\n",
    "print('Used in: LLaMA, Mistral, Falcon, GPT-NeoX')\n",
    "print()\n",
    "print('Ready to use in experiments.')\n",
    "print('Import: from PE.rope import RoPEPositionalEncoding')"
   ]
  }
 ]
}
