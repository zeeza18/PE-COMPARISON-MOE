{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-00",
   "metadata": {},
   "source": [
    "# DAPE — Data-Adaptive Positional Encoding Demo\n",
    "\n",
    "**Paper:** Zheng et al. (NeurIPS 2024) — *DAPE: Data-Adaptive Positional Encoding for Length Extrapolation*  \n",
    "**Formula:** `PE_DAPE(x,i) = (1 + alpha(x)) * PE_sin(i) + beta(x)`  \n",
    "**Properties:** Dynamic (adapts per input) | Small adaptation network | Variable-length friendly  \n",
    "**Note:** This is a simplified additive version for unified comparison with other PE methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPEPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Data-Adaptive PE (simplified version, inspired by Zheng et al. NeurIPS 2024).\n",
    "    Modulates sinusoidal PE using a small network conditioned on input statistics.\n",
    "\n",
    "    PE_DAPE(x, i) = (1 + alpha(x)) * PE_sin(i) + beta(x)\n",
    "    where [alpha, beta] = AdaptNet([mean, std, norm_length])\n",
    "    '''\n",
    "    def __init__(self, d_model, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Base sinusoidal encoding\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe_base', pe.unsqueeze(0))  # (1, max_seq_len, d_model)\n",
    "\n",
    "        # Adaptation network: [mean, std, norm_len] -> (alpha, beta) per dim\n",
    "        self.adapt_net = nn.Sequential(\n",
    "            nn.Linear(3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2 * d_model),\n",
    "        )\n",
    "\n",
    "        adapt_params = sum(p.numel() for p in self.adapt_net.parameters())\n",
    "        print(f'DAPE: base=sinusoidal (0 params) + adapt_net ({adapt_params} params)')\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        with torch.no_grad():\n",
    "            stats = torch.stack([\n",
    "                x.mean(dim=[1, 2]),\n",
    "                x.std(dim=[1, 2]).clamp(min=1e-6),\n",
    "                torch.full((batch_size,), seq_len / 512.0, device=x.device),\n",
    "            ], dim=1)  # (batch, 3)\n",
    "\n",
    "        mod = self.adapt_net(stats)                       # (batch, 2*d_model)\n",
    "        alpha = mod[:, :self.d_model].unsqueeze(1)        # (batch, 1, d_model)\n",
    "        beta  = mod[:, self.d_model:].unsqueeze(1)        # (batch, 1, d_model)\n",
    "\n",
    "        pe_adaptive = (1 + alpha) * self.pe_base[:, :seq_len, :] + beta\n",
    "        return self.dropout(x + pe_adaptive)\n",
    "\n",
    "print('DAPEPositionalEncoding defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check — verify different inputs get different PEs\n",
    "d_model, seq_len = 64, 50\n",
    "pe_layer = DAPEPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "# Two inputs with very different statistics\n",
    "x_zeros = torch.zeros(1, seq_len, d_model)        # mean=0, std=0\n",
    "x_large = torch.randn(1, seq_len, d_model) * 10   # larger scale\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_zeros = pe_layer(x_zeros)\n",
    "    out_large = pe_layer(x_large)\n",
    "\n",
    "# If DAPE is truly adaptive, PE component should differ\n",
    "pe_zeros = out_zeros - x_zeros\n",
    "pe_large = out_large - x_large\n",
    "\n",
    "diff = (pe_zeros - pe_large).abs().mean().item()\n",
    "print(f'Input shape : {x_zeros.shape}')\n",
    "print(f'Learnable params: {sum(p.numel() for p in pe_layer.parameters())}')\n",
    "print(f'\\nPE difference between x_zeros and x_large: {diff:.4f}')\n",
    "print('(Should be > 0 if DAPE adapts to input statistics)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap — compare base sinusoidal vs DAPE-adapted PE\n",
    "d_model, seq_len = 64, 60\n",
    "pe_layer = DAPEPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "x = torch.randn(1, seq_len, d_model)\n",
    "with torch.no_grad():\n",
    "    encoded = pe_layer(x)\n",
    "\n",
    "pe_component = (encoded - x).numpy()[0]       # (seq_len, d_model) — adaptive PE\n",
    "base_pe = pe_layer.pe_base[0, :seq_len, :].numpy()  # (seq_len, d_model) — sinusoidal base\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "im0 = axes[0].imshow(base_pe.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Dimension')\n",
    "axes[0].set_title('Base Sinusoidal PE (static)')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "im1 = axes[1].imshow(pe_component.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Dimension')\n",
    "axes[1].set_title('DAPE Adapted PE (dynamic, changes per input)')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_dape_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: demo_dape_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "adapt_params = 3*32 + 32 + 32*2*d_model + 2*d_model\n",
    "print('=== DAPE Summary ===')\n",
    "print(f'Learnable parameters: {sum(p.numel() for p in DAPEPositionalEncoding(d_model, dropout=0.0).parameters())}')\n",
    "print('Base: sinusoidal (no params) + adaptation network')\n",
    "print('Input features: [mean, std, normalized_length]')\n",
    "print('Output: per-dimension scale (alpha) and shift (beta)')\n",
    "print('Dynamic: YES — different inputs get different PEs')\n",
    "print('Length-adaptive: YES')\n",
    "print('Original paper: Zheng et al. NeurIPS 2024')\n",
    "print()\n",
    "print('Ready to use in experiments.')\n",
    "print('Import: from PE.dape import DAPEPositionalEncoding')"
   ]
  }
 ]
}
