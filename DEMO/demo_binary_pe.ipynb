{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-00",
   "metadata": {},
   "source": [
    "# Binary Positional Encoding — Demo\n",
    "\n",
    "**Idea:** Represent position `i` as its binary bit pattern, then project to `d_model`.  \n",
    "**Formula:** `bit_k(i) = (i >> k) & 1`, projected via `Linear(n_bits, d_model)`  \n",
    "**Properties:** No trig ops (fast) | Deterministic | One learnable projection layer  \n",
    "**Best for:** Short sequences, edge/resource-constrained devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Binary PE: encodes position i as its binary bit pattern,\n",
    "    then projects from n_bits -> d_model via a learned linear layer.\n",
    "    '''\n",
    "    def __init__(self, d_model, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        n_bits = math.ceil(math.log2(max_seq_len + 1))\n",
    "\n",
    "        # Build binary table: position i -> n_bits bit vector\n",
    "        pe_binary = torch.zeros(max_seq_len, n_bits)\n",
    "        for pos in range(max_seq_len):\n",
    "            for bit in range(n_bits):\n",
    "                pe_binary[pos, bit] = float((pos >> bit) & 1)\n",
    "\n",
    "        self.register_buffer('pe_binary', pe_binary.unsqueeze(0))  # (1, max_seq_len, n_bits)\n",
    "        self.projection = nn.Linear(n_bits, d_model, bias=False)   # learned projection\n",
    "\n",
    "        print(f'Binary PE: {n_bits} bits -> {d_model} dims  |  projection params: {n_bits * d_model}')\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pe = self.projection(self.pe_binary[:, :seq_len, :])  # (1, seq_len, d_model)\n",
    "        x = x + pe\n",
    "        return self.dropout(x)\n",
    "\n",
    "print('BinaryPositionalEncoding defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check — shape test\n",
    "d_model, seq_len, batch = 64, 50, 4\n",
    "pe_layer = BinaryPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "x = torch.zeros(batch, seq_len, d_model)\n",
    "out = pe_layer(x)\n",
    "\n",
    "print(f'Input shape : {x.shape}')\n",
    "print(f'Output shape: {out.shape}')\n",
    "print(f'Learnable params: {sum(p.numel() for p in pe_layer.parameters())}')\n",
    "\n",
    "# Show first 5 position binary patterns (before projection)\n",
    "print('\\nFirst 5 positions binary patterns (raw bits):')\n",
    "n_bits = pe_layer.pe_binary.shape[-1]\n",
    "for pos in range(5):\n",
    "    bits = [int(pe_layer.pe_binary[0, pos, b].item()) for b in range(n_bits)]\n",
    "    print(f'  pos {pos}: {bits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap — visualize raw binary patterns and projected PE\n",
    "d_model, seq_len = 64, 60\n",
    "pe_layer = BinaryPositionalEncoding(d_model, max_seq_len=512, dropout=0.0)\n",
    "\n",
    "# Raw binary patterns (before projection)\n",
    "raw_binary = pe_layer.pe_binary[0, :seq_len, :].detach().numpy()  # (seq_len, n_bits)\n",
    "\n",
    "# Projected PE (after linear layer)\n",
    "dummy = torch.zeros(1, seq_len, d_model)\n",
    "with torch.no_grad():\n",
    "    projected = pe_layer(dummy)\n",
    "pe_matrix = projected[0].numpy()  # (seq_len, d_model)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "# Raw binary heatmap\n",
    "axes[0].imshow(raw_binary.T, aspect='auto', cmap='binary', origin='lower')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Bit Index')\n",
    "axes[0].set_title('Binary Patterns (raw bits, before projection)')\n",
    "\n",
    "# Projected PE heatmap\n",
    "im = axes[1].imshow(pe_matrix.T, aspect='auto', cmap='RdYlBu', origin='lower')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Dimension')\n",
    "axes[1].set_title('Binary PE Heatmap (after projection to d_model)')\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_binary_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: demo_binary_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "d_model, max_seq_len = 64, 512\n",
    "n_bits = math.ceil(math.log2(max_seq_len + 1))\n",
    "print('=== Binary PE Summary ===')\n",
    "print(f'Bits needed for {max_seq_len} positions: {n_bits}')\n",
    "print(f'Projection params: {n_bits} x {d_model} = {n_bits * d_model}')\n",
    "print(f'No trig functions: YES (just bit shifts)')\n",
    "print(f'Generalizes to unseen lengths: YES (bits work for any pos)')\n",
    "print(f'Task-adaptive: NO (pattern is fixed, projection is learned)')\n",
    "print()\n",
    "print('Ready to use in experiments.')\n",
    "print('Import: from PE.binary_pe import BinaryPositionalEncoding')"
   ]
  }
 ]
}
