{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-00",
   "metadata": {},
   "source": [
    "# Phase 1 Experiment — Dataset 5: Adult Census\n",
    "\n",
    "**Task:** Income Prediction (>50K or <=50K)  \n",
    "**Type:** TABULAR (14 features, treated as a sequence of 14 tokens)  \n",
    "**Classes:** 2 (binary)  \n",
    "**Source:** UCI ML Repository / Kaggle\n",
    "\n",
    "**Novel aspect:** Each tabular feature is treated as a token at position 0..13.  \n",
    "PE here encodes **feature identity** (which feature is at this position), not word order.  \n",
    "Tests whether PE helps transformers distinguish between different tabular feature positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from PE.sinusoidal_pe import SinusoidalPositionalEncoding\n",
    "from PE.binary_pe    import BinaryPositionalEncoding\n",
    "from PE.rope         import RoPEPositionalEncoding\n",
    "from PE.learned_pe   import LearnedPositionalEncoding\n",
    "from PE.dape         import DAPEPositionalEncoding\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Dataset — tabular, each feature = one token position\n",
    "    n_classes   = 2\n",
    "    n_features  = 14      # Adult Census has 14 features -> seq_len = 14\n",
    "    max_seq_len = 14\n",
    "    test_size   = 0.2\n",
    "    val_size    = 0.1\n",
    "\n",
    "    # Model (each feature projected to d_model)\n",
    "    d_model  = 64         # smaller model for tabular data\n",
    "    n_heads  = 4\n",
    "    n_layers = 2\n",
    "    d_ff     = 128\n",
    "    dropout  = 0.1\n",
    "\n",
    "    batch_size = 128\n",
    "    lr         = 1e-3\n",
    "    epochs     = 30\n",
    "    seed       = 42\n",
    "\n",
    "cfg = Config()\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "print(f'Config: seq_len={cfg.max_seq_len} (14 features as tokens), n_classes={cfg.n_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Adult Census dataset from UCI via pandas\n",
    "# If running for the first time, dataset will be downloaded from UCI\n",
    "ADULT_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "\n",
    "COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "    'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income'\n",
    "]\n",
    "\n",
    "print('Loading Adult Census dataset...')\n",
    "try:\n",
    "    df = pd.read_csv(ADULT_URL, names=COLUMNS, na_values=' ?', skipinitialspace=True)\n",
    "    print(f'Loaded from UCI. Shape: {df.shape}')\n",
    "except Exception:\n",
    "    # Fallback: try sklearn datasets\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    adult = fetch_openml('adult', version=2, as_frame=True)\n",
    "    df = adult.frame\n",
    "    df.columns = [c.lower().replace('-', '_') for c in df.columns]\n",
    "    print(f'Loaded from sklearn. Shape: {df.shape}')\n",
    "\n",
    "# Preprocess\n",
    "df = df.dropna()\n",
    "y = (df['income'].astype(str).str.contains('>50K')).astype(int).values\n",
    "X = df.drop(columns=['income'])\n",
    "\n",
    "# Encode categoricals\n",
    "for col in X.select_dtypes(include=['object', 'category']).columns:\n",
    "    X[col] = pd.factorize(X[col])[0]\n",
    "\n",
    "X = X.values.astype(np.float32)\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "cfg.n_features = X.shape[1]\n",
    "cfg.max_seq_len = cfg.n_features\n",
    "\n",
    "print(f'Features: {cfg.n_features} | Positive rate: {y.mean():.2%}')\n",
    "\n",
    "# Split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=cfg.test_size, random_state=cfg.seed, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=cfg.val_size, random_state=cfg.seed, stratify=y_temp)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular dataset — each sample is (n_features,), treated as a sequence of n_features tokens\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X: (N, n_features) -> store as (N, n_features, 1) for per-feature projection\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(-1)  # (N, n_features, 1)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "val_ds   = TabularDataset(X_val,   y_val)\n",
    "test_ds  = TabularDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)} | Val batches: {len(val_loader)}')\n",
    "print(f'Input shape: {train_ds[0][0].shape}  (n_features=seq_len, feature_val=1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for tabular data\n",
    "# Each feature value (scalar) is projected to d_model, then PE is added\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads; self.d_k = d_model // n_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model); self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model); self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        Q = self.W_q(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        out = torch.matmul(self.dropout(F.softmax(scores, dim=-1)), V)\n",
    "        return self.W_o(out.transpose(1, 2).contiguous().view(B, T, D))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_ff, d_model))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.ln1 = nn.LayerNorm(d_model); self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x + self.drop(self.attn(x)))\n",
    "        return self.ln2(x + self.drop(self.ff(x)))\n",
    "\n",
    "class TabularTransformer(nn.Module):\n",
    "    '''\n",
    "    Transformer for tabular data.\n",
    "    Each feature is projected from scalar (1) -> d_model,\n",
    "    then PE is added to distinguish feature positions.\n",
    "    '''\n",
    "    def __init__(self, n_features, d_model, n_heads, n_layers, d_ff, pe_class, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.feature_proj = nn.Linear(1, d_model)        # project each feature value\n",
    "        self.pe = pe_class(d_model, n_features, dropout)  # PE over feature positions\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, 1)                 # binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, n_features, 1)\n",
    "        x = self.feature_proj(x)   # (B, n_features, d_model)\n",
    "        x = self.pe(x)\n",
    "        for b in self.blocks: x = b(x)\n",
    "        return self.head(self.norm(x.mean(dim=1)))\n",
    "\n",
    "print('TabularTransformer defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train(); total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X).squeeze(-1)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += ((torch.sigmoid(logits) > 0.5).long() == y.long()).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval(); all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            preds = (torch.sigmoid(model(X.to(device)).squeeze(-1)) > 0.5).long().cpu()\n",
    "            all_preds.extend(preds.tolist()); all_labels.extend(y.long().tolist())\n",
    "    return accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "print('Training/eval functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE_METHODS = {\n",
    "    'sinusoidal': SinusoidalPositionalEncoding,\n",
    "    'binary':     BinaryPositionalEncoding,\n",
    "    'rope':       RoPEPositionalEncoding,\n",
    "    'learned':    LearnedPositionalEncoding,\n",
    "    'dape':       DAPEPositionalEncoding,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for pe_name, pe_class in PE_METHODS.items():\n",
    "    print(f'\\n=== {pe_name.upper()} PE ===')\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    model = TabularTransformer(\n",
    "        n_features=cfg.n_features, d_model=cfg.d_model,\n",
    "        n_heads=cfg.n_heads, n_layers=cfg.n_layers,\n",
    "        d_ff=cfg.d_ff, pe_class=pe_class, dropout=cfg.dropout\n",
    "    ).to(device)\n",
    "    print(f'  Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
    "    best_acc, best_f1, t0 = 0, 0, time.time()\n",
    "    for epoch in range(cfg.epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_acc, val_f1 = evaluate(model, val_loader)\n",
    "        scheduler.step()\n",
    "        if val_acc > best_acc: best_acc, best_f1 = val_acc, val_f1\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'  Ep {epoch+1:02d} | loss {train_loss:.4f} | train {train_acc:.4f} | val_acc {val_acc:.4f}')\n",
    "    elapsed = time.time() - t0\n",
    "    results[pe_name] = {'accuracy': best_acc, 'f1': best_f1, 'time_s': elapsed}\n",
    "    print(f'  Done in {elapsed:.1f}s — best val acc: {best_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*65)\n",
    "print('PHASE 1 RESULTS — Adult Census (TABULAR, 14 features as sequence)')\n",
    "print('='*65)\n",
    "print(f'{\"PE Method\":<15} {\"Accuracy\":>10} {\"F1\":>10} {\"Time (s)\":>10}')\n",
    "print('-'*65)\n",
    "best_acc_val = max(v['accuracy'] for v in results.values())\n",
    "for pe_name, m in results.items():\n",
    "    marker = ' <-- BEST' if m['accuracy'] == best_acc_val else ''\n",
    "    print(f'{pe_name:<15} {m[\"accuracy\"]:>10.4f} {m[\"f1\"]:>10.4f} {m[\"time_s\"]:>10.1f}{marker}')\n",
    "print('='*65)\n",
    "\n",
    "names  = list(results.keys())\n",
    "accs   = [results[n]['accuracy'] for n in names]\n",
    "f1s    = [results[n]['f1']       for n in names]\n",
    "colors = ['#4C72B0', '#DD8452', '#55A868', '#C44E52', '#8172B2']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].bar(names, accs, color=colors);  axes[0].set_title('Accuracy — Adult Census');  axes[0].tick_params(axis='x', rotation=15)\n",
    "axes[1].bar(names, f1s,  color=colors);  axes[1].set_title('F1 Score — Adult Census');  axes[1].tick_params(axis='x', rotation=15)\n",
    "plt.suptitle('Phase 1: PE Comparison on Adult Census (TABULAR — 14 feature positions)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results_adult.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: results_adult.png')"
   ]
  }
 ]
}
